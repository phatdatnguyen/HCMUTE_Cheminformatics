{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2d6e30",
   "metadata": {},
   "source": [
    "# Chapter 11. Deep Learning in Chemistry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09f3a0",
   "metadata": {},
   "source": [
    "## 11.3. Application of Deep Learning in Chemistry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa334069",
   "metadata": {},
   "source": [
    "MLP networks can be used to predict various chemical systems. In the following section, we will apply MLP to predict molecular properties and reaction outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096bd7c",
   "metadata": {},
   "source": [
    "### 11.3.1. Prediction of Molecular Properies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e3f8f",
   "metadata": {},
   "source": [
    "#### 11.3.1.1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92baff2b",
   "metadata": {},
   "source": [
    "In this section, we will build an MLP network to predict the solubility of molecules:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40d781",
   "metadata": {},
   "source": [
    "**a. Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23675fff",
   "metadata": {},
   "source": [
    "**b. Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06742390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_file_path = './datasets/Solubility.csv'\n",
    "df = pd.read_csv(data_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03752bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of SMILES\n",
    "smiles_arr = df['smiles'].to_numpy()\n",
    "\n",
    "# Get the output column\n",
    "y = df['solubility'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696d75d",
   "metadata": {},
   "source": [
    "**c. Feature extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract a list of features from a molecule\n",
    "def extract_features(mol):\n",
    "    features = []\n",
    "    features.append(Descriptors.MolWt(mol))          # molecular weight\n",
    "    features.append(Descriptors.NumHeteroatoms(mol)) # number of heteroatoms\n",
    "    features.append(Descriptors.RingCount(mol))      # number of rings\n",
    "    features.append(Descriptors.NumHAcceptors(mol))  # number of hydrogen bond donor\n",
    "    features.append(Descriptors.NumHDonors(mol))     # number of hydrogen bond accepter\n",
    "    features.append(Descriptors.FractionCSP3(mol))   # fraction of SP3-hybridized carbons\n",
    "    features.append(Descriptors.TPSA(mol))           # topological polar surface area\n",
    "    features.append(Descriptors.MolLogP(mol))        # partition coefficient\n",
    "    features.append(Descriptors.MolMR(mol))        # molar refractivity\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6684a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of features for molecules\n",
    "x = []\n",
    "\n",
    "# Loop through the SMILES list\n",
    "pbar = tqdm(range(len(smiles_arr)))\n",
    "for i in pbar:\n",
    "    # Get the SMILES for each molecule\n",
    "    smiles = smiles_arr[i]\n",
    "    \n",
    "    # Create a molecule object from the SMILES\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Get descriptors\n",
    "    features = extract_features(mol)\n",
    "    x.append(features)\n",
    "    \n",
    "    # Print progress\n",
    "    pbar.set_description('{}/{} molecules processed |'.format(i + 1, len(smiles_arr)))\n",
    "    \n",
    "# Convert list to numpy array\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c22f6f",
   "metadata": {},
   "source": [
    "**d. Data processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750dbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2aef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output scalers\n",
    "input_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "output_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale the data\n",
    "x_scaled = input_scaler.fit_transform(x)\n",
    "y_scaled = output_scaler.fit_transform(y.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(x_scaled, y_scaled, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "x_train_scaled, x_val_scaled, y_train_scaled, y_val_scaled = train_test_split(x_train_scaled, y_train_scaled, test_size=0.25, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d0440",
   "metadata": {},
   "source": [
    "**e. Create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regression model class\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, n_inputs, n_layers, n_hiddens, n_outputs):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.hiddens = nn.ModuleList()\n",
    "        self.hiddens.append(nn.Linear(n_inputs, n_hiddens))\n",
    "        for _ in range(1, n_layers):\n",
    "            self.hiddens.append(nn.Linear(n_hiddens, n_hiddens))\n",
    "        self.output = nn.Linear(n_hiddens, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for hidden in self.hiddens:\n",
    "            x = torch.relu(hidden(x))\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "n_inputs = x_train_scaled.shape[1]\n",
    "n_layers = 2\n",
    "n_hiddens = 32\n",
    "n_outputs = 1\n",
    "model = RegressionModel(n_inputs, n_layers, n_hiddens, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e237be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the device to train the model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Send the model and all tensors to device (except y_test_scaled because it is not needed)\n",
    "model.float().to(device)\n",
    "x_train_scaled = torch.tensor(x_train_scaled, device=device, dtype=torch.float)\n",
    "y_train_scaled = torch.tensor(y_train_scaled, device=device, dtype=torch.float)\n",
    "x_val_scaled = torch.tensor(x_val_scaled, device=device, dtype=torch.float)\n",
    "y_val_scaled = torch.tensor(y_val_scaled, device=device, dtype=torch.float)\n",
    "x_test_scaled = torch.tensor(x_test_scaled, device=device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2ab0a",
   "metadata": {},
   "source": [
    "**f. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731bf785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cdb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train function\n",
    "def train(x, y):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cfd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the validation function\n",
    "@torch.no_grad()\n",
    "def validation(x, y):\n",
    "     # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e76755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of losses for visualization\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = train(x_train_scaled, y_train_scaled.unsqueeze(1))\n",
    "    val_loss = validation(x_val_scaled, y_val_scaled.unsqueeze(1))\n",
    "    \n",
    "    # Add loss to lists for visualization\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Print progress\n",
    "    progress_bar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE loss values over time\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e500e1f",
   "metadata": {},
   "source": [
    "**g. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward the test set\n",
    "y_pred_scaled = model(x_test_scaled)\n",
    "\n",
    "# Scale output back to original range\n",
    "y_pred = output_scaler.inverse_transform(y_pred_scaled.detach().cpu().numpy().reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Transform the test set back to original scale\n",
    "y_test = output_scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', edgecolor='k', alpha=0.7, s=40)\n",
    "plt.plot(y_test, y_test, color='red', linewidth=2)  # Ideal line for perfect predictions\n",
    "plt.xlabel('Actual Solubility')\n",
    "plt.ylabel('Predicted Solubility')\n",
    "plt.title('Predictions vs Actual')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b55760c",
   "metadata": {},
   "source": [
    "**h. Save and load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = 'mlp_model'\n",
    "file_name = f'{model_name}_{num_epochs}.ckpt'\n",
    "torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f9175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "file_name = f'{model_name}_1000.ckpt'\n",
    "loaded_model = RegressionModel(n_inputs, n_layers, n_hiddens, n_outputs)\n",
    "loaded_model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355a6d8",
   "metadata": {},
   "source": [
    "#### 11.3.1.2. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852a0e3",
   "metadata": {},
   "source": [
    "In this section, we will build an MLP network to predict whether a molecule can penetrate the blood-brain barrier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517164e",
   "metadata": {},
   "source": [
    "**a. Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb11c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "from rdkit import Chem\n",
    "from rdkit.Avalon import pyAvalonTools\n",
    "from rdkit.Chem import Descriptors\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7c90a",
   "metadata": {},
   "source": [
    "**b. Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_file_path = './datasets/BBBP.csv'\n",
    "df = pd.read_csv(data_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296dd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of SMILES\n",
    "smiles_arr = df['smiles'].to_numpy()\n",
    "\n",
    "# Get the output column\n",
    "output_arr = df['p_np'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c016a",
   "metadata": {},
   "source": [
    "**c. Feature extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract a list of features from a molecule\n",
    "def extract_features(mol):\n",
    "    avalon_fp = pyAvalonTools.GetAvalonFP(mol, nBits=512) # Avalon fingerprint\n",
    "    features = np.array(avalon_fp)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of features for molecules\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# Loop through the SMILES list\n",
    "pbar = tqdm(range(len(smiles_arr)))\n",
    "for i in pbar:\n",
    "    # Get the SMILES for each molecule\n",
    "    smiles = smiles_arr[i]\n",
    "    \n",
    "    # Create a molecule object from the SMILES\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Get descriptors (skip if can't extract)\n",
    "    try:\n",
    "        features = extract_features(mol)\n",
    "        x.append(features)\n",
    "        y.append(output_arr[i])\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Print progress\n",
    "    pbar.set_description('{}/{} molecules processed |'.format(i + 1, len(smiles_arr)))\n",
    "    \n",
    "# Convert list to numpy array\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384bab17",
   "metadata": {},
   "source": [
    "**d. Data processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcf2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1813813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a variance threshold to remove input columns with only one value.\n",
    "var_thresholder = VarianceThreshold(threshold=0.01)\n",
    "x_var_thresh = var_thresholder.fit_transform(x)\n",
    "\n",
    "# Apply PCA to reduce the dimensionality\n",
    "pca = PCA(n_components=32)\n",
    "x_pca = pca.fit_transform(x_var_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467b6f6",
   "metadata": {},
   "source": [
    "**e. Create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classification model class\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, n_inputs, n_layers, n_hiddens, n_outputs):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.hiddens = nn.ModuleList()\n",
    "        self.hiddens.append(nn.Linear(n_inputs, n_hiddens))\n",
    "        for _ in range(1, n_layers):\n",
    "            self.hiddens.append(nn.Linear(n_hiddens, n_hiddens))\n",
    "        self.output = nn.Linear(n_hiddens, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for hidden in self.hiddens:\n",
    "            x = torch.sigmoid(hidden(x))\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89af10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "n_inputs = x_train.shape[1]\n",
    "n_layers = 3\n",
    "n_hiddens = 64\n",
    "n_outputs = 1\n",
    "model = ClassificationModel(n_inputs, n_layers, n_hiddens, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fecf99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the device to train the model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Send the model and all tensors to device (except y_test because it is not needed)\n",
    "model.float().to(device)\n",
    "\n",
    "x_train = torch.tensor(x_train, device=device, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train, device=device, dtype=torch.float)\n",
    "x_val = torch.tensor(x_val, device=device, dtype=torch.float)\n",
    "y_val = torch.tensor(y_val, device=device, dtype=torch.float)\n",
    "x_test = torch.tensor(x_test, device=device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5086a",
   "metadata": {},
   "source": [
    "**f. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train function\n",
    "def train(x, y):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7521d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the validation function\n",
    "def validation(x, y):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of losses for visualization\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = train(x_train, y_train.unsqueeze(1))\n",
    "    val_loss = validation(x_val, y_val.unsqueeze(1))\n",
    "    \n",
    "    # Add loss to lists for visualization\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "        \n",
    "    # Print progress\n",
    "    progress_bar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a76692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE loss values over time\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('BCE loss with logits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca625f0",
   "metadata": {},
   "source": [
    "**g. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward the test set\n",
    "logits = model(x_test)\n",
    "probabilities = torch.sigmoid(logits)\n",
    "y_pred = torch.round(probabilities).detach().cpu().numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb03fb9",
   "metadata": {},
   "source": [
    "**h. Make prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new molecule\n",
    "mol = Chem.MolFromSmiles('CCO') # ethanol\n",
    "\n",
    "# Extract features\n",
    "features = extract_features(mol)\n",
    "features = np.array(features)\n",
    "\n",
    "# Apply variance threshold\n",
    "features_var_thresh = var_thresholder.transform(features.reshape(1, -1))\n",
    "\n",
    "# Apply PCA\n",
    "features_pca = pca.transform(features_var_thresh)\n",
    "\n",
    "# Convert to tensor\n",
    "x_pred = torch.tensor(features_pca, device=device, dtype=torch.float)\n",
    "\n",
    "# Run model forward\n",
    "logits = model(x_pred)\n",
    "probabilities = torch.sigmoid(logits)\n",
    "y_pred = torch.round(probabilities).int().detach().cpu().numpy().reshape(-1)[0]\n",
    "\n",
    "# Show the prediction\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ccdf1",
   "metadata": {},
   "source": [
    "**i. Save and load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = 'mlp_model'\n",
    "file_name = f'./{model_name}_{num_epochs}.ckpt'\n",
    "torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8dfad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "file_name = f'./{model_name}_100.ckpt'\n",
    "loaded_model = ClassificationModel(n_inputs, n_layers, n_hiddens, n_outputs)\n",
    "loaded_model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eca547",
   "metadata": {},
   "source": [
    "### 11.3.2. Prediction of Reaction Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd5de4",
   "metadata": {},
   "source": [
    "In this section, we will build an MLP network to predict the yield of C-N coupling reactions (Buchwald-Hartwig reaction):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3080e17a",
   "metadata": {},
   "source": [
    "**a. Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed77260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f114b98",
   "metadata": {},
   "source": [
    "**b. Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_file_path = './datasets/BuchwaldHartwigReactionYield.csv'\n",
    "df = pd.read_csv(data_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb714e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of SMILES\n",
    "ligand_smiles_arr = df['Ligand'].to_numpy()\n",
    "additive_smiles_arr = df['Additive'].to_numpy()\n",
    "base_smiles_arr = df['Base'].to_numpy()\n",
    "aryl_halide_smiles_arr = df['Aryl halide'].to_numpy()\n",
    "\n",
    "# Get the output\n",
    "y = df['Yield'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc7379",
   "metadata": {},
   "source": [
    "**c. Feature extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract a list of features from a molecule\n",
    "def extract_features(mol):\n",
    "    ap_fp = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol, nBits=512) # Atom-pairs fingerprint\n",
    "    \n",
    "    return ap_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea98307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of features for molecules\n",
    "x = []\n",
    "\n",
    "# Loop through the SMILES list\n",
    "pbar = tqdm(range(len(df)))\n",
    "for i in pbar:\n",
    "    # Create molecule objects from their SMILES\n",
    "    ligand = Chem.MolFromSmiles(ligand_smiles_arr[i])\n",
    "    additive = Chem.MolFromSmiles(additive_smiles_arr[i])\n",
    "    base = Chem.MolFromSmiles(base_smiles_arr[i])\n",
    "    aryl_halide = Chem.MolFromSmiles(aryl_halide_smiles_arr[i])\n",
    "    \n",
    "    # Get the atom-pairs fingerprints for each compound\n",
    "    ligand_features = extract_features(ligand)\n",
    "    additive_features = extract_features(additive)\n",
    "    base_features = extract_features(base)\n",
    "    aryl_halide_features = extract_features(aryl_halide)\n",
    "    \n",
    "    # Concatenate the fingerprints then add them to the list\n",
    "    x.append(ligand_features + additive_features + base_features + aryl_halide_features)\n",
    "    \n",
    "    # Print progress\n",
    "    pbar.set_description('{}/{} reactions processed |'.format(i + 1, len(df)))\n",
    "    \n",
    "# Convert list to numpy array\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9de99b",
   "metadata": {},
   "source": [
    "**d. Data processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec08f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22dde0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a variance threshold to remove input columns with only one value.\n",
    "var_thresholder = VarianceThreshold(threshold=0.01)\n",
    "x_var_thresh = var_thresholder.fit_transform(x)\n",
    "\n",
    "# Define output scaler and scale output data\n",
    "output_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = output_scaler.fit_transform(y.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Apply PCA to reduce the dimensionality\n",
    "pca = PCA(n_components=64)\n",
    "x_pca = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a020b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train_scaled, y_test_scaled = train_test_split(x_pca, y_scaled, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "x_train, x_val, y_train_scaled, y_val_scaled = train_test_split(x_train, y_train_scaled, test_size=0.25, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f7bbf",
   "metadata": {},
   "source": [
    "**e. Create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regression model class\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, n_inputs, n_layers, n_hiddens, n_outputs):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.hiddens = nn.ModuleList()\n",
    "        self.hiddens.append(nn.Linear(n_inputs, n_hiddens))\n",
    "        for _ in range(1, n_layers):\n",
    "            self.hiddens.append(nn.Linear(n_hiddens, n_hiddens))\n",
    "        self.output = nn.Linear(n_hiddens, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for hidden in self.hiddens:\n",
    "            x = torch.relu(hidden(x))\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "n_inputs = x_train.shape[1]\n",
    "n_layers = 3\n",
    "n_hiddens = 256\n",
    "n_outputs = 1\n",
    "model = RegressionModel(n_inputs, n_layers, n_hiddens, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ebdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the device to train the model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Send the model and all tensors to device (except y_test_scaled because it is not needed)\n",
    "model.float().to(device)\n",
    "x_train = torch.tensor(x_train, device=device, dtype=torch.float)\n",
    "y_train_scaled = torch.tensor(y_train_scaled, device=device, dtype=torch.float)\n",
    "x_val = torch.tensor(x_val, device=device, dtype=torch.float)\n",
    "y_val_scaled = torch.tensor(y_val_scaled, device=device, dtype=torch.float)\n",
    "x_test = torch.tensor(x_test, device=device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007fed4c",
   "metadata": {},
   "source": [
    "**f. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train function\n",
    "def train(x, y):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the validation function\n",
    "@torch.no_grad()\n",
    "def validation(x, y):\n",
    "     # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0aa03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of losses for visualization\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = train(x_train, y_train_scaled.unsqueeze(1))\n",
    "    val_loss = validation(x_val, y_val_scaled.unsqueeze(1))\n",
    "    \n",
    "    # Add loss to lists for visualization\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Print progress\n",
    "    progress_bar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a88509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize MSE loss values over time\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ccd7e",
   "metadata": {},
   "source": [
    "**g. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward the test set\n",
    "y_pred_scaled = model(x_test)\n",
    "\n",
    "# Scale output back to original range\n",
    "y_pred = output_scaler.inverse_transform(y_pred_scaled.detach().cpu().numpy().reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Transform the test set back to original scale\n",
    "y_test = output_scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45bd672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4cd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', edgecolor='k', alpha=0.7, s=40)\n",
    "plt.plot(y_test, y_test, color='red', linewidth=2)  # Ideal line for perfect predictions\n",
    "plt.xlabel('Actual Yield')\n",
    "plt.ylabel('Predicted Yield')\n",
    "plt.title('Predictions vs Actual')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8384dba8",
   "metadata": {},
   "source": [
    "**h. Save and load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = 'mlp_rxn_model'\n",
    "file_name = f'./{model_name}_{num_epochs}.ckpt'\n",
    "torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359b69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "file_name = f'./{model_name}_1000.ckpt'\n",
    "loaded_model = RegressionModel(n_inputs, n_layers, n_hiddens, n_outputs)\n",
    "loaded_model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0ef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "244.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
